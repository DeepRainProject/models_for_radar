{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "taken-rouge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 08:53:26.822417: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quiet-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = True\n",
    "light_rain_threshold = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "judicial-acrylic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load path: /p/project/deepacf/deeprain/rojascampos1/data/sauerland/original/\n",
      "Save path: /p/scratch/deepacf/deeprain/rojascampos1/data/radar_enhancement/hres/\n"
     ]
    }
   ],
   "source": [
    "years = [str(year) for year in range(2011,2019)] \n",
    "months = [str(month).zfill(2) for month in range(1,13)]\n",
    "\n",
    "res = 'hres' #Can be hres or lres\n",
    "\n",
    "load_path = '/p/project/deepacf/deeprain/rojascampos1/data/sauerland/original/'\n",
    "save_path = '/p/scratch/deepacf/deeprain/rojascampos1/data/radar_enhancement/' + res\n",
    "\n",
    "if data_augmentation:\n",
    "    save_path = save_path + '_augmented/'\n",
    "else:\n",
    "    save_path = save_path + '/'\n",
    "\n",
    "\n",
    "print('Load path:', load_path)\n",
    "print('Save path:', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "athletic-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "## List to create just one file\n",
    "time_list = []\n",
    "radar_list = []\n",
    "cosmo_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incredible-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 01 : (247, 36, 36, 143) ---> (247, 72, 72) Same timepoints? True\n",
      "2011 02 : (224, 36, 36, 143) ---> (224, 72, 72) Same timepoints? True\n",
      "2011 03 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2011 04 : (238, 36, 36, 143) ---> (238, 72, 72) Same timepoints? True\n",
      "2011 05 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2011 06 : (239, 36, 36, 143) ---> (239, 72, 72) Same timepoints? True\n",
      "2011 07 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2011 08 : (243, 36, 36, 143) ---> (243, 72, 72) Same timepoints? True\n",
      "2011 09 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2011 10 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2011 11 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2011 12 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2012 01 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2012 02 : (224, 36, 36, 143) ---> (224, 72, 72) Same timepoints? True\n",
      "2012 03 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2012 04 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2012 05 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2012 06 : (239, 36, 36, 143) ---> (239, 72, 72) Same timepoints? True\n",
      "2012 07 : (243, 36, 36, 143) ---> (243, 72, 72) Same timepoints? True\n",
      "2012 08 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2012 09 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2012 10 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2012 11 : (239, 36, 36, 143) ---> (239, 72, 72) Same timepoints? True\n",
      "2012 12 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2013 01 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2013 02 : (224, 36, 36, 143) ---> (224, 72, 72) Same timepoints? True\n",
      "2013 03 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2013 04 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2013 05 : (242, 36, 36, 143) ---> (242, 72, 72) Same timepoints? True\n",
      "2013 06 : (233, 36, 36, 143) ---> (233, 72, 72) Same timepoints? True\n",
      "2013 07 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2013 08 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2013 09 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2013 10 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2013 11 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2013 12 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2014 01 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2014 02 : (224, 36, 36, 143) ---> (224, 72, 72) Same timepoints? True\n",
      "2014 03 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2014 04 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2014 05 : (246, 36, 36, 143) ---> (246, 72, 72) Same timepoints? True\n",
      "2014 06 : (238, 36, 36, 143) ---> (238, 72, 72) Same timepoints? True\n",
      "2014 07 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2014 08 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2014 09 : (239, 36, 36, 143) ---> (239, 72, 72) Same timepoints? True\n",
      "2014 10 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2014 11 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2014 12 : (247, 36, 36, 143) ---> (247, 72, 72) Same timepoints? True\n",
      "2015 01 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2015 02 : (224, 36, 36, 143) ---> (224, 72, 72) Same timepoints? True\n",
      "2015 03 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2015 04 : (232, 36, 36, 143) ---> (232, 72, 72) Same timepoints? True\n",
      "2015 05 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2015 06 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2015 07 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2015 08 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2015 09 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2015 10 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2015 11 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2015 12 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2016 01 : (247, 36, 36, 143) ---> (247, 72, 72) Same timepoints? True\n",
      "2016 02 : (224, 36, 36, 143) ---> (224, 72, 72) Same timepoints? True\n",
      "2016 03 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2016 04 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2016 05 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2016 06 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2016 07 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2016 08 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2016 09 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2016 10 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2016 11 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2016 12 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2017 01 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2017 02 : (224, 36, 36, 143) ---> (224, 72, 72) Same timepoints? True\n",
      "2017 03 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2017 04 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2017 05 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2017 06 : (238, 36, 36, 143) ---> (238, 72, 72) Same timepoints? True\n",
      "2017 07 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2017 08 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2017 09 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2017 10 : (246, 36, 36, 143) ---> (246, 72, 72) Same timepoints? True\n",
      "2017 11 : (238, 36, 36, 143) ---> (238, 72, 72) Same timepoints? True\n",
      "2017 12 : (246, 36, 36, 143) ---> (246, 72, 72) Same timepoints? True\n",
      "2018 01 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2018 02 : (215, 36, 36, 143) ---> (215, 72, 72) Same timepoints? True\n",
      "2018 03 : (248, 36, 36, 143) ---> (248, 72, 72) Same timepoints? True\n",
      "2018 04 : (240, 36, 36, 143) ---> (240, 72, 72) Same timepoints? True\n",
      "2018 05 : (112, 36, 36, 143) ---> (112, 72, 72) Same timepoints? True\n"
     ]
    }
   ],
   "source": [
    "## Iterates over years and months, creates files for each month\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        \n",
    "        ## Stops if in end\n",
    "        if (year == '2018' and month == '06'):\n",
    "            break\n",
    "        \n",
    "        cosmo_time = np.load(load_path+'/'+year+'/'+'ensemble_stats_'+year+'_'+month+'_time.npy')\n",
    "        cosmo_data = np.load(load_path+'/'+year+'/'+'ensemble_stats_'+year+'_'+month+'_data.npy')\n",
    "        radar_time = np.load(load_path+'/'+year+'/'+'radar_'+res+'_'+year+'_'+month+'_time.npy')\n",
    "        radar_data = np.load(load_path+'/'+year+'/'+'radar_'+res+'_'+year+'_'+month+'_data.npy')\n",
    "        \n",
    "        ## Check for temporal compatibility\n",
    "        mask = np.isin(radar_time, cosmo_time)\n",
    "        radar_time = radar_time[mask]\n",
    "        radar_data = radar_data[mask]\n",
    "        print(year, month, ':', cosmo_data.shape , '--->', radar_data.shape, 'Same timepoints?', np.array_equal(cosmo_time, radar_time))\n",
    "        \n",
    "        ## Creates one big file\n",
    "        time_list.append(radar_time)\n",
    "        radar_list.append(radar_data)\n",
    "        cosmo_list.append(cosmo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "numerous-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save objects as one file\n",
    "np.save(save_path+'00_time.npy', np.concatenate(time_list))\n",
    "np.save(save_path+'00_y.npy', np.concatenate(radar_list, axis=0))\n",
    "np.save(save_path+'00_x.npy', np.concatenate(cosmo_list, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "union-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "del radar_list, time_list, cosmo_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-federal",
   "metadata": {},
   "source": [
    "### Splits train, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accepted-mambo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = (21427, 36, 36, 143) ---> y = (21427, 72, 72)\n"
     ]
    }
   ],
   "source": [
    "time = np.load(save_path + '00_time.npy')\n",
    "x = np.load(save_path + '00_x.npy')\n",
    "c = x[:,:,:,97]\n",
    "y = np.load(save_path + '00_y.npy')\n",
    "print('x =', x.shape, '---> y =', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chronic-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 3.929621505577076 % of timesteps\n"
     ]
    }
   ],
   "source": [
    "## exclude nans\n",
    "nans = np.isnan(y)\n",
    "n_nans = np.sum(np.sum(nans, axis=1), axis=1)\n",
    "mask = n_nans == 0\n",
    "print('Removed', (np.sum(~mask)/y.shape[0]) * 100 , '% of timesteps' ) \n",
    "x = x[mask]\n",
    "c = c[mask]\n",
    "y = y[mask]\n",
    "time = time[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seventh-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common elements from groups = 0\n"
     ]
    }
   ],
   "source": [
    "## Split taking 4 days per month\n",
    "time = pd.DatetimeIndex(time)\n",
    "mask_test  = np.isin(time.day, [1, 9, 17, 25])\n",
    "mask_valid = np.isin(time.day, [5, 13, 21, 28])\n",
    "mask_train = np.logical_or(mask_test, mask_valid) ## Is it right?\n",
    "mask_train = np.logical_not(mask_train)\n",
    "print('Number of common elements from groups =', np.sum(mask_test * mask_valid * mask_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "southwest-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: x = (15189, 36, 36, 143) ---> y = (15189, 72, 72) cosmo: (15189, 36, 36) time: (15189,)\n",
      "Test: x = (2671, 36, 36, 143) ---> y = (2671, 72, 72) cosmo: (2671, 36, 36) time: (2671,)\n",
      "Valid: x = (2725, 36, 36, 143) ---> y = (2725, 72, 72) cosmo: (2725, 36, 36) time: (2725,)\n"
     ]
    }
   ],
   "source": [
    "tst_x = x[mask_test]\n",
    "tst_c = c[mask_test]\n",
    "tst_y = y[mask_test]\n",
    "tst_t = time[mask_test]\n",
    "\n",
    "vld_x = x[mask_valid]\n",
    "vld_c = c[mask_valid]\n",
    "vld_y = y[mask_valid]\n",
    "vld_t = time[mask_valid]\n",
    "\n",
    "trn_x = x[mask_train]\n",
    "trn_c = c[mask_train]\n",
    "trn_y = y[mask_train]\n",
    "trn_t = time[mask_train]\n",
    "\n",
    "print('Train: x =', trn_x.shape, '---> y =', trn_y.shape, 'cosmo:', trn_c.shape, 'time:', trn_t.shape)\n",
    "print('Test: x =', tst_x.shape, '---> y =', tst_y.shape,  'cosmo:', tst_c.shape, 'time:', tst_t.shape)\n",
    "print('Valid: x =', vld_x.shape, '---> y =', vld_y.shape, 'cosmo:', vld_c.shape, 'time:', vld_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5169c35c-8109-4f0f-bb4e-23ff1861b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_path + '01_trn_t.npy', trn_t)\n",
    "np.save(save_path + '01_tst_t.npy', tst_t)\n",
    "np.save(save_path + '01_vld_t.npy', vld_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intimate-smooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: x = (15189, 36, 36, 143) ---> y = (15189, 72, 72)\n",
      "Test: x = (2671, 36, 36, 143) ---> y = (2671, 72, 72)\n",
      "Valid: x = (2725, 36, 36, 143) ---> y = (2725, 72, 72)\n"
     ]
    }
   ],
   "source": [
    "x_mean = np.mean(trn_x, axis=0)\n",
    "x_std  = np.std(trn_x, axis=0)\n",
    "\n",
    "trn_x = (trn_x - x_mean)/x_std\n",
    "tst_x = (tst_x - x_mean)/x_std\n",
    "vld_x = (vld_x - x_mean)/x_std\n",
    "\n",
    "print('Train: x =', trn_x.shape, '---> y =', trn_y.shape)\n",
    "print('Test: x =', tst_x.shape, '---> y =', tst_y.shape)\n",
    "print('Valid: x =', vld_x.shape, '---> y =', vld_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "rational-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_path + '01_trn_x.npy', trn_x)\n",
    "np.save(save_path + '01_trn_y.npy', trn_y)\n",
    "np.save(save_path + '01_trn_c.npy', trn_c)\n",
    "\n",
    "np.save(save_path + '01_tst_x.npy', tst_x)\n",
    "np.save(save_path + '01_tst_y.npy', tst_y)\n",
    "np.save(save_path + '01_tst_c.npy', tst_c)\n",
    "\n",
    "np.save(save_path + '01_vld_x.npy', vld_x)\n",
    "np.save(save_path + '01_vld_y.npy', vld_y)\n",
    "np.save(save_path + '01_vld_c.npy', vld_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "medieval-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "del time, x, y, c, trn_x, trn_y, trn_c, tst_x, tst_y, tst_c, vld_x, vld_y, vld_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-messenger",
   "metadata": {},
   "source": [
    "# Convolutional approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_x = np.load(save_path + '01_trn_x.npy')\n",
    "trn_y = np.load(save_path + '01_trn_y.npy')\n",
    "tst_x = np.load(save_path + '01_tst_x.npy')\n",
    "tst_y = np.load(save_path + '01_tst_y.npy')\n",
    "vld_x = np.load(save_path + '01_vld_x.npy')\n",
    "vld_y = np.load(save_path + '01_vld_y.npy')\n",
    "print('Train: x =', trn_x.shape, '---> y =', trn_y.shape)\n",
    "print('Test: x =', tst_x.shape, '---> y =', tst_y.shape)\n",
    "print('Valid: x =', vld_x.shape, '---> y =', vld_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-setup",
   "metadata": {},
   "source": [
    "### Write tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d3667-b6bd-43e3-906a-b80c08523468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tfrecords(x, y, n_records, name):\n",
    "    \n",
    "    x = np.array_split(x, n_records)\n",
    "    y = np.array_split(y, n_records)\n",
    "    \n",
    "    ## Write n_records files  \n",
    "    for i, (forecast, prec) in enumerate(zip(x, y)):\n",
    "\n",
    "        ## Inside each file do:\n",
    "        with tf.io.TFRecordWriter('/p/scratch/deepacf/deeprain/rojascampos1/data/radar_enhancement/hres_tminusone/'+ name + '/{:03d}'.format(i) +'.tfrecord') as tfrecord:\n",
    "\n",
    "            for idx in range(2, forecast.shape[0]):\n",
    "                \n",
    "\n",
    "                features = {\n",
    "                    \n",
    "                    'feature' : tf.train.Feature(float_list=tf.train.FloatList( value = forecast[idx-2:idx].flatten() )),\n",
    "                    'label'   : tf.train.Feature(float_list=tf.train.FloatList( value = prec[idx].flatten()     ))}\n",
    "\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "                tfrecord.write(example.SerializeToString())\n",
    "\n",
    "        print(name, str(i)+'/'+str(n_records)+' wrote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tfrecords(trn_x, trn_y, 100, 'train_set')    \n",
    "write_tfrecords(tst_x, tst_y, 10, 'test_set')\n",
    "write_tfrecords(vld_x, vld_y, 10, 'validation_set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyDeepLearning-1.1",
   "language": "python",
   "name": "pydeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
